2025-04-29 16:09:04,772 - INFO - âœ… æ—¥å¿—åˆå§‹åŒ–å®Œæˆ | è·¯å¾„: train_logs/20250429_160904.log
2025-04-29 16:09:04,794 - INFO - âœ… æ—¥å¿—åˆå§‹åŒ–å®Œæˆ | è·¯å¾„: train_logs/20250429_160904.log
2025-04-29 16:09:04,794 - INFO - ğŸ“Œ âœ¨ å½“å‰è®­ç»ƒé…ç½®
2025-04-29 16:09:04,794 - INFO -     out_dir: out
2025-04-29 16:09:04,794 - INFO -     epochs: 1
2025-04-29 16:09:04,794 - INFO -     batch_size: 32
2025-04-29 16:09:04,794 - INFO -     learning_rate: 0.0005
2025-04-29 16:09:04,794 - INFO -     device: cpu
2025-04-29 16:09:04,794 - INFO -     dtype: bfloat16
2025-04-29 16:09:04,794 - INFO -     use_wandb: False
2025-04-29 16:09:04,794 - INFO -     wandb_project: MiniQA-Pretrain
2025-04-29 16:09:04,794 - INFO -     num_workers: 1
2025-04-29 16:09:04,794 - INFO -     ddp: False
2025-04-29 16:09:04,794 - INFO -     accumulation_steps: 8
2025-04-29 16:09:04,794 - INFO -     grad_clip: 1.0
2025-04-29 16:09:04,794 - INFO -     warmup_iters: 0
2025-04-29 16:09:04,794 - INFO -     log_interval: 100
2025-04-29 16:09:04,794 - INFO -     save_interval: 100
2025-04-29 16:09:04,794 - INFO -     local_rank: -1
2025-04-29 16:09:04,794 - INFO -     hidden_size: 512
2025-04-29 16:09:04,794 - INFO -     num_hidden_layer: 8
2025-04-29 16:09:04,794 - INFO -     max_seq_len: 512
2025-04-29 16:09:04,794 - INFO -     use_moe: False
2025-04-29 16:09:04,794 - INFO -     data_path: /root/LLMDataset/MilitaryIssues.jsonl
2025-04-29 16:09:04,794 - INFO -     tokenizer_path: /root/MiniQA/model/PretrainTokenizer
2025-04-29 16:09:04,840 - INFO - âš ï¸ WandB æœªå¯ç”¨æˆ–éä¸»è¿›ç¨‹
2025-04-29 16:09:04,840 - INFO - âš¡ï¸ åˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒ...
2025-04-29 16:09:04,841 - INFO - âœˆï¸ æ¯è½®è¿­ä»£æ­¥æ•°ï¼š1
2025-04-29 16:09:06,489 - INFO - Epoch:[1/1](0/1) loss:502.890 lr:0.000550000000 ETA:0.0min
